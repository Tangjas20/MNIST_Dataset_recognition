{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'saveable_objects_from_trackable' from 'tensorflow.python.training.saving.saveable_object_util' (C:\\Users\\Jason\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\__init__.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracking\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\tracking\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf.__internal__.tracking namespace.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaveable_object_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saveable_objects_from_trackable\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautotrackable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTrackable\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckpointInitialValue\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'saveable_objects_from_trackable' from 'tensorflow.python.training.saving.saveable_object_util' (C:\\Users\\Jason\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_data_path = os.getcwd() + \"\\\\data\"\n",
    "print(os.listdir(current_data_path))\n",
    "\n",
    "import gzip\n",
    "def replaceZeroes(data):\n",
    "    min_nonzero= min(data[np.nonzero(data)])\n",
    "    data[data == 0] = min_nonzero\n",
    "    return data\n",
    "\n",
    "\n",
    "with gzip.open(current_data_path + '\\\\train-images-idx3-ubyte (2).gz','r') as f:\n",
    "    image_size = 28\n",
    "    num_images = 60000\n",
    "    import numpy as np\n",
    "    f.read(16)\n",
    "    buf = f.read(image_size * image_size * num_images)\n",
    "    x_train = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    x_train = x_train.reshape(num_images, image_size, image_size, 1)\n",
    "\n",
    "with gzip.open(current_data_path + '\\\\train-labels-idx1-ubyte (1).gz','r') as f:\n",
    "    image_size = 28\n",
    "    num_images = 60000\n",
    "\n",
    "    import numpy as np\n",
    "    f.read(16)\n",
    "\n",
    "    buf = f.read(image_size * image_size * num_images)\n",
    "    x_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    x_labels = x_labels.reshape(num_images, image_size, image_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "image = np.asarray(x_train[15001]).squeeze()\n",
    "plt.imshow(image, \"Greys\")\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247eb0dfd90>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 15005 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train.shape\n",
    "image_size = 28\n",
    "num_train_images = 60000\n",
    "num_test_images = 10000\n",
    "\n",
    "x_train = x_train.reshape(num_images, image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(num_test_images, image_size, image_size, 1).astype('float32')\n",
    "input_shape = (num_images, num_images, 1)\n",
    "#Normalising data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25198320028,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten()) \u001b[38;5;66;03m# Flattening the 2D arrays for fully connected layers\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax))\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\PycharmProjects\\ELEC3612_Assign_2\\venv\\lib\\site-packages\\keras\\backend.py:1920\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator:\n\u001b[0;32m   1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   1919\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape, minval\u001b[38;5;241m=\u001b[39mminval, maxval\u001b[38;5;241m=\u001b[39mmaxval, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m-> 1920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_legacy_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25198320028,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2032 - accuracy: 0.9384\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0796 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0542 - accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0417 - accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0336 - accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0268 - accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0166 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247e4de6bb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0609094612300396, 0.9850000143051147]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
